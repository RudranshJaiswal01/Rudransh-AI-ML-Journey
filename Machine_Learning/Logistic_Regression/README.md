# Logistic Regression from Scratch

This project demonstrates an implementation of **Logistic Regression** from scratch using Python. The goal is to gain a deeper understanding of how logistic regression works, including the sigmoid function, cost function, and gradient descent.

## ðŸ“‚ Project Structure

- `LogisticRegression_scratch.ipynb` - Google Colab notebook implementing logistic regression step by step.

## ðŸ“š Concepts Covered

- Logistic Regression for Binary Classification

- Sigmoid Function

- Cost Function

- Gradient Descent Optimization

## ðŸ“¦ Libraries Used

- **NumPy** - Used for numerical operations such as matrix calculations and applying mathematical functions.

- **Pandas** - Used for handling and preprocessing datasets.

- **Matplotlib** - Used for visualizing results and decision boundaries.

- **Scikit-Learn** - Used for splitting the dataset into training and testing sets (`train_test_split`) and evaluating model performance (`accuracy_score`).

## ðŸ“œ Usage

You can open and run the notebook directly in **Google Colab** using the following link:

[Open in Colab](https://colab.research.google.com/drive/1CJ3n3U8eOqfem2WQ_FRgSTiJcI-p_KNc?usp=sharing)

**Or**

1. Upload `LogisticRegression_scratch.ipynb` to your Google Drive and open in Colab or Jupyter notebook.
2. Execute the cells to follow the implementation.

## ðŸ“Š Results & Insights

- Implemented logistic regression without external ML libraries.
- Used gradient descent to optimise the model parameters.
- Used sigmoid function to introduce non-linearity and get probabilistic outputs.

## ðŸ“œ License

This project is for educational purposes. Feel free to use and modify the code.

---

